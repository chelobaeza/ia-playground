{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import error, spaces, utils, Env\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del problema\n",
    "\n",
    "El siguiente ejemplo consiste en un Ambiente (Room). La temperatura de la habitación cambia debido a la temperatura externa ambiente (se asume de forma desconocida). La habitación cuenta con un equipo de Aire Acondicionado controlado por un Agente. El objetivo de este Agente es mantener la temperatura en 0 grados. El Aire Acondicionado puede cambiar la temperatura en 0, 1, 2 o 3 grados ya sea frío o calor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiente\n",
    "\n",
    "El ambiente (Room) está simulado por el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Room(Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.observation_space = spaces.Box(low=-20, high=40, shape=(), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(7, start=-3)\n",
    "                  \n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "        self.initial_random = self.observation_space.sample()\n",
    "        self.external_temp = 0\n",
    "        self.external_temp = self._temp_variation()\n",
    "        self.temp = self.external_temp\n",
    "        return self.temp\n",
    "    \n",
    "    def step(self, action):\n",
    "        delta_temp = self._temp_variation()\n",
    "        self.external_temp += delta_temp\n",
    "        self.temp += delta_temp + action\n",
    "        self.step_count += 1\n",
    "        return self.temp\n",
    "\n",
    "    def _temp_variation(self):\n",
    "        x = self.initial_random + self.step_count\n",
    "        return np.float64('%.2f'%(20 * np.sin(x/10))) - self.external_temp \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Room()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agente Model Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentModelBased():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.prev_obs = 0\n",
    "        \n",
    "    def lookup(self, obs):\n",
    "    \n",
    "        diff = obs - self.prev_obs\n",
    "        self.prev_obs = obs\n",
    "\n",
    "        # state hot (obs > 0) & temp rising (obs - prev_obs > 0)\n",
    "        if obs > 0 and (diff > 0):\n",
    "            return int(np.maximum(-3.0, -obs))\n",
    "\n",
    "        # state hot (obs > 0) & temp lowering (obs - prev_obs <= 0)\n",
    "        if obs > 0 and (diff <= 0):\n",
    "            return int(np.maximum(-1.0, -obs))\n",
    "\n",
    "        # state cold (obs < 0) & temp rising (obs - prev_obs > 0)\n",
    "        if obs < 0 and (diff > 0):\n",
    "            return int(np.minimum(1.0, -obs))\n",
    "\n",
    "        # state cold (obs > 0) & temp lowering (obs - prev_obs <= 0)\n",
    "        if obs < 0 and (diff <= 0):\n",
    "            return int(np.minimum(3.0, -obs))\n",
    "\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test AgentModelBased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentModelBased()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "external_res = []\n",
    "agent_res = []\n",
    "action_list = []\n",
    "total_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, total_steps):  \n",
    "    \n",
    "    # solamente para evaluar la evolución de la temperatura de la habitación con y sin agente\n",
    "    # la temperatura de la habitación sin el agente es igual a la temperatura exterior\n",
    "    \n",
    "    external_temp = env.external_temp\n",
    "    external_res.append(external_temp)\n",
    "    \n",
    "    # decisión y acción del agente\n",
    "    \n",
    "    prev_obs = obs\n",
    "    action = agent.lookup(obs)\n",
    "    action_list.append(action)\n",
    "    obs = env.step(action)\n",
    "    agent_res.append(obs)  \n",
    "    \n",
    "    print('External:', external_temp, '\\n','Prev. Obs:', prev_obs, '-> Action:', action, '-> Room:', obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficando los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axhline(color='black')                                  #Temperatura ideal\n",
    "plt.plot(range(0, total_steps), agent_res, color='red')     #Temperatura con el agente\n",
    "plt.plot(range(0, total_steps), external_res, color='blue') #Temperatura sin agente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métrica de Performance\n",
    "Una posible métrica de performance, podría ser ver la temperatura media del ambiente con la acción del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Temperatura media con el agente: \", np.mean(agent_res))\n",
    "print(\"Temperatura media sin el agente: \", np.mean(external_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra posible métrica de performance, es evaluar para cada instante de tiempo (step) cuanto difiere la temperatura obtenida de la objetivo=0. Esto se puede hacer con mean_squared_error o mean_absolute_error. \n",
    "Comparemos la métrica obtenida por el agente contra la métrica obtenida sin un agente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_temp = np.zeros(total_steps)\n",
    "print(\"Variación media con el agente: \", mean_absolute_error(goal_temp, agent_res))\n",
    "print(\"Variación media sin el agente: \", mean_absolute_error(goal_temp, external_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Consumo medio con el agente: \", np.mean(np.abs(action_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
